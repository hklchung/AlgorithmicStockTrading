{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeats=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['place_id', 'LineCategory']\n",
      "['Total Product Sale', 'No_Of_StatusCO', 'No_Of_Invoiced', 'No_Of_WIP', '1st_frequent_OpCtr', '1st_frequent_No_Of_OpCtr', '2st_frequent_OpCtr', '2st_frequent_No_Of_OpCtr', '1st_frequent_No_Of_ItemType', '2st_frequent_No_Of_ItemType', '3st_frequent_No_Of_ItemType', '4st_frequent_No_Of_ItemType', '5st_frequent_No_Of_ItemType', '1st_frequent_No_Of_ActionType', '2st_frequent_No_Of_ActionType', '3st_frequent_No_Of_ActionType', 'DistinctCount_PartNo', '1st_frequent_No_Of_LineType', 'Total Service Sale', 'Total Qty', 'Total Cost', 'Total GrossProfit', '1stLineCateSales', '2stLineCateSales', '3stLineCateSales', '4stLineCateSales', 'place_id', 'LineCategory']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eyan\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int32, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "raw_data=pd.read_csv('Beauty.csv', engine='python', skipfooter=1)\n",
    "\n",
    "data_train=raw_data.drop('year', axis = 1)\n",
    "data_train=data_train.drop('month', axis = 1)\n",
    "\n",
    "# fill missing value with -999\n",
    "data_train=data_train.fillna(-999)\n",
    "\n",
    "# labelEncoder 'place_id' and 'LineCategory'\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "categorical=['place_id', 'LineCategory']\n",
    "print(categorical)\n",
    "\n",
    "for value in categorical:\n",
    "    le.fit(data_train[value].astype(str))\n",
    "    data_train[value]=le.transform(data_train[value].astype(str))\n",
    "    \n",
    "\n",
    "    \n",
    "# Scaler numerical features\n",
    "numerical = list(data_train.select_dtypes(include=['int64']).columns.values)+list(data_train.select_dtypes(include=['float64']).columns.values)\n",
    "numerical.append('place_id')\n",
    "numerical.append('LineCategory')\n",
    "print(numerical)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler_target = MinMaxScaler()\n",
    "\n",
    "scaler_target.fit_transform(data_train['Total Product Sale'].values.reshape(-1, 1))\n",
    "data_train[numerical] = scaler.fit_transform(data_train[numerical])\n",
    "\n",
    "# one-hot other categorical features\n",
    "data_train = pd.get_dummies(data_train)\n",
    "\n",
    "# prepare data for LSTM\n",
    "dataset=np.array(data_train)\n",
    "target=dataset[:,[0,1,2]]\n",
    "Features = []\n",
    "Targets = []\n",
    "InputSteps=10\n",
    "OutputSteps=3\n",
    "for index in range(len(dataset) - InputSteps): # maxmimum date = lastest date - sequence length\n",
    "    Features.append(dataset[index: index + InputSteps]) # index : index + steps\n",
    "\n",
    "for index in range(len(target) - InputSteps-OutputSteps): # maxmimum date = lastest date - sequence length\n",
    "            Targets.append(target[index+InputSteps: index +InputSteps+OutputSteps]) # index : index + steps\n",
    "        \n",
    "Features=np.array(Features)\n",
    "Targets=np.array(Targets)\n",
    "\n",
    "Label=0\n",
    "Features_New=[]\n",
    "Targets_New=[]\n",
    "for i in range(len(Targets)):\n",
    "    Label=0\n",
    "    for j in range(1,InputSteps):\n",
    "        if not(Features[i,0,0]==Features[i,j,0] and Features[i,0,1]==Features[i,j,1]):\n",
    "            Label=1\n",
    "            #print(Features[i])\n",
    "    for t in range(OutputSteps):\n",
    "        if not(Features[i,0,0]==Targets[i,t,0] and Features[i,0,1]==Targets[i,t,1]):\n",
    "            Label=1\n",
    "           # print(Targets[i])\n",
    "    \n",
    "    if Label==0:\n",
    "        Features_New.append(Features[i])\n",
    "        Targets_New.append(Targets[i])\n",
    "        \n",
    "Features_New=np.array(Features_New)\n",
    "Targets_New=np.array(Targets_New)\n",
    "\n",
    "Targets_New=Targets_New[:,:,2]\n",
    "\n",
    "Targets_New=numpy.reshape(Targets_New, (Targets_New.shape[0], Targets_New.shape[1],1))\n",
    "\n",
    "trainLen=round(len(Targets_New)*0.8)\n",
    "trainX=Features_New[:trainLen]\n",
    "testX=Features_New[trainLen:]\n",
    "trainY=Targets_New[:trainLen]\n",
    "testY=Targets_New[trainLen:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 8955.766732582562\n",
      "RMSE 9817.943344066907\n",
      "RMSE 9496.484770134404\n",
      "RMSE 8820.275721426262\n",
      "RMSE 9054.380675103037\n",
      "Mean of RMSE 9228.970248662634\n",
      "Minutes spent 25.184386944770814\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "RMSE_total=0\n",
    "for i in range(repeats):\n",
    "\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "    model.add(RepeatVector(3))\n",
    "    model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    # fit model\n",
    "    model.fit(trainX, trainY, epochs=30, verbose=0)\n",
    "\n",
    "    yhat = model.predict(testX, verbose=0)\n",
    "    RMSE_1=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,0,:]),scaler_target.inverse_transform(yhat[:,0,:])))\n",
    "    RMSE_2=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,1,:]),scaler_target.inverse_transform(yhat[:,1,:])))                                 \n",
    "    RMSE_3=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,2,:]),scaler_target.inverse_transform(yhat[:,2,:])))                                    \n",
    "    RMSE_final=(RMSE_1+RMSE_2+RMSE_3)/3\n",
    "    print('RMSE',RMSE_final)\n",
    "    RMSE_total+=RMSE_final\n",
    "    \n",
    "print('Mean of RMSE',RMSE_total/repeats)\n",
    "print('Minutes spent', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 9721.458050084184\n",
      "RMSE 9036.004193464154\n",
      "RMSE 9697.604463791728\n",
      "RMSE 9774.51198433968\n",
      "RMSE 9509.36989505077\n",
      "Mean of RMSE 9547.789717346104\n",
      "Minutes spent 30.064014883836112\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "RMSE_total=0\n",
    "for i in range(repeats):\n",
    "\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "    model.add(RepeatVector(3))\n",
    "    model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    # fit model\n",
    "    model.fit(trainX, trainY, epochs=30, verbose=0)\n",
    "\n",
    "    yhat = model.predict(testX, verbose=0)\n",
    "    RMSE_1=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,0,:]),scaler_target.inverse_transform(yhat[:,0,:])))\n",
    "    RMSE_2=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,1,:]),scaler_target.inverse_transform(yhat[:,1,:])))                                 \n",
    "    RMSE_3=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,2,:]),scaler_target.inverse_transform(yhat[:,2,:])))                                    \n",
    "    RMSE_final=(RMSE_1+RMSE_2+RMSE_3)/3\n",
    "    print('RMSE',RMSE_final)\n",
    "    RMSE_total+=RMSE_final\n",
    "    \n",
    "print('Mean of RMSE',RMSE_total/repeats)\n",
    "print('Minutes spent', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Fit train set well on cost fuhction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Tune learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 10132.590704611612\n",
      "RMSE 10503.421022600922\n",
      "RMSE 9722.632583203995\n",
      "RMSE 11873.42111664614\n",
      "RMSE 10164.10312859578\n",
      "Learning Rate 0.0001\n",
      "Mean of RMSE 10479.23371113169\n",
      "RMSE 10424.27182608274\n",
      "RMSE 9151.939613256423\n",
      "RMSE 9593.07782016842\n",
      "RMSE 9510.762219773516\n",
      "RMSE 9257.272766899508\n",
      "Learning Rate 0.001\n",
      "Mean of RMSE 9587.464849236121\n",
      "RMSE 9438.900782192295\n",
      "RMSE 11688.730062749071\n",
      "RMSE 10277.58025220658\n",
      "RMSE 11275.633856593506\n",
      "RMSE 10704.276325557776\n",
      "Learning Rate 0.01\n",
      "Mean of RMSE 10677.024255859846\n",
      "RMSE 9663.4190440268\n",
      "RMSE 12585.814620285017\n",
      "RMSE 9249.939007674771\n",
      "RMSE 9402.72154764886\n",
      "RMSE 9479.53798392717\n",
      "Learning Rate 0.1\n",
      "Mean of RMSE 10076.286440712523\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-2bcb6cf8b37c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mRMSE_1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscaler_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mRMSE_2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscaler_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mRMSE_3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscaler_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \"\"\"\n\u001b[0;32m    238\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 239\u001b[1;33m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[0;32m    240\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 573\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "LearningRates = [0.0001,0.001, 0.01,0.1,1]\n",
    "for LearningRate in LearningRates:\n",
    "\n",
    "    RMSE_total=0\n",
    "    for i in range(repeats):\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, activation='relu', input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "        model.add(RepeatVector(3))\n",
    "        model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "        model.add(TimeDistributed(Dense(1)))\n",
    "        optimizer = optimizers.Adam(lr=LearningRate)\n",
    "        model.compile(optimizer=optimizer, loss='mse')\n",
    "        # fit model\n",
    "        model.fit(trainX, trainY, epochs=30, verbose=0)\n",
    "\n",
    "        yhat = model.predict(testX, verbose=0)\n",
    "        RMSE_1=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,0,:]),scaler_target.inverse_transform(yhat[:,0,:])))\n",
    "        RMSE_2=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,1,:]),scaler_target.inverse_transform(yhat[:,1,:])))                                 \n",
    "        RMSE_3=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,2,:]),scaler_target.inverse_transform(yhat[:,2,:])))                                    \n",
    "        RMSE_final=(RMSE_1+RMSE_2+RMSE_3)/3\n",
    "        print('RMSE',RMSE_final)\n",
    "        RMSE_total+=RMSE_final\n",
    "    print('Learning Rate',LearningRate)\n",
    "    print('Mean of RMSE',RMSE_total/repeats)\n",
    "    \n",
    "print('Minutes spent', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 9243.308953045487\n",
      "RMSE 8942.614342444771\n",
      "RMSE 9428.424072767282\n",
      "RMSE 8947.18875858138\n",
      "RMSE 9508.024589253684\n",
      "Learning Rate 0.001\n",
      "Mean of RMSE 9213.912143218522\n",
      "RMSE 9403.166992439901\n",
      "RMSE 8929.570431956645\n",
      "RMSE 10770.416862283651\n",
      "RMSE 10422.091943509766\n",
      "RMSE 9364.288005710796\n",
      "Learning Rate 0.003\n",
      "Mean of RMSE 9777.906847180153\n",
      "RMSE 9352.878752887287\n",
      "RMSE 10287.801808062368\n",
      "RMSE 8851.596350311456\n",
      "RMSE 9159.3188684037\n",
      "RMSE 9112.600831992902\n",
      "Learning Rate 0.005\n",
      "Mean of RMSE 9352.839322331543\n",
      "RMSE 9879.352220579422\n",
      "RMSE 9035.443541995459\n",
      "RMSE 13292.967888872896\n",
      "RMSE 9484.525654376981\n",
      "RMSE 9411.922784744489\n",
      "Learning Rate 0.007\n",
      "Mean of RMSE 10220.842418113849\n",
      "RMSE 8996.79670348446\n",
      "RMSE 9361.455824528648\n",
      "RMSE 8814.125997857218\n",
      "RMSE 9580.947583503834\n",
      "RMSE 11252.06170552115\n",
      "Learning Rate 0.01\n",
      "Mean of RMSE 9601.077562979062\n",
      "RMSE 9001.557381315988\n",
      "RMSE 9581.162375900107\n",
      "RMSE 8668.74302101584\n",
      "RMSE 10447.328702339018\n",
      "RMSE 13592.957742015735\n",
      "Learning Rate 0.03\n",
      "Mean of RMSE 10258.349844517339\n",
      "RMSE 22554.234066304736\n",
      "RMSE 16867.5335139431\n",
      "RMSE 14971.086722137368\n",
      "RMSE 8948.96922759225\n",
      "RMSE 10640.561627258656\n",
      "Learning Rate 0.05\n",
      "Mean of RMSE 14796.47703144722\n",
      "RMSE 13847.025154749941\n",
      "RMSE 10338.297540563788\n",
      "RMSE 9738.865732519052\n",
      "RMSE 9344.772159063463\n",
      "RMSE 8763.217227307394\n",
      "Learning Rate 0.07\n",
      "Mean of RMSE 10406.435562840727\n",
      "Minutes spent 724.8105227867762\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "LearningRates = [0.001,0.003,0.005,0.007, 0.01,0.03,0.05,0.07]\n",
    "for LearningRate in LearningRates:\n",
    "\n",
    "    RMSE_total=0\n",
    "    for i in range(repeats):\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, activation='relu', input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "        model.add(RepeatVector(3))\n",
    "        model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "        model.add(TimeDistributed(Dense(1)))\n",
    "        optimizer = optimizers.Adam(lr=LearningRate)\n",
    "        model.compile(optimizer=optimizer, loss='mse')\n",
    "        # fit model\n",
    "        model.fit(trainX, trainY, epochs=30, verbose=0)\n",
    "\n",
    "        yhat = model.predict(testX, verbose=0)\n",
    "        RMSE_1=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,0,:]),scaler_target.inverse_transform(yhat[:,0,:])))\n",
    "        RMSE_2=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,1,:]),scaler_target.inverse_transform(yhat[:,1,:])))                                 \n",
    "        RMSE_3=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,2,:]),scaler_target.inverse_transform(yhat[:,2,:])))                                    \n",
    "        RMSE_final=(RMSE_1+RMSE_2+RMSE_3)/3\n",
    "        print('RMSE',RMSE_final)\n",
    "        RMSE_total+=RMSE_final\n",
    "    print('Learning Rate',LearningRate)\n",
    "    print('Mean of RMSE',RMSE_total/repeats)\n",
    "    \n",
    "print('Minutes spent', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion: learning rate-0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Tune \"mini-batch size\" and \"num of hidder units\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 9783.681589242331\n",
      "RMSE 9941.977344999186\n",
      "RMSE 10722.731304949988\n",
      "RMSE 9415.684394990583\n",
      "RMSE 11516.291016236164\n",
      "batch_size 32\n",
      "Mean of RMSE 10276.07313008365\n",
      "RMSE 9929.697473252863\n",
      "RMSE 10191.74393639272\n",
      "RMSE 13291.306799822773\n",
      "RMSE 10220.676014969069\n",
      "RMSE 10185.074817184306\n",
      "batch_size 64\n",
      "Mean of RMSE 10763.699808324347\n",
      "RMSE 10396.326712969905\n",
      "RMSE 10811.686843224054\n",
      "RMSE 11768.237427865126\n",
      "RMSE 10063.609025979365\n",
      "RMSE 12142.095877409374\n",
      "batch_size 128\n",
      "Mean of RMSE 11036.391177489564\n",
      "RMSE 9523.679931368142\n",
      "RMSE 9892.845968027987\n",
      "RMSE 10397.995691849559\n",
      "RMSE 10596.463996816034\n",
      "RMSE 11756.243535479902\n",
      "batch_size 256\n",
      "Mean of RMSE 10433.445824708326\n",
      "RMSE 10394.310947661586\n",
      "RMSE 9669.264280048277\n",
      "RMSE 11943.879461527044\n",
      "RMSE 9674.731357499495\n",
      "RMSE 10269.45180287542\n",
      "batch_size 512\n",
      "Mean of RMSE 10390.327569922363\n",
      "RMSE 9220.150564731352\n",
      "RMSE 9546.386163583213\n",
      "RMSE 9829.445057251587\n",
      "RMSE 13396.828811496422\n",
      "RMSE 9200.361738730358\n",
      "batch_size 1024\n",
      "Mean of RMSE 10238.634467158587\n",
      "Minutes spent 495.612662812074\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "batch_sizes = [32,64,128,256,512,1024]\n",
    "neurons = 32\n",
    "for batch_size in batch_sizes:\n",
    "\n",
    "    RMSE_total=0\n",
    "    for i in range(repeats):\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(neurons, activation='relu', input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "        model.add(RepeatVector(3))\n",
    "        model.add(LSTM(neurons, activation='relu', return_sequences=True))\n",
    "        model.add(TimeDistributed(Dense(1)))\n",
    "        optimizer = optimizers.Adam(lr=0.001)\n",
    "        model.compile(optimizer=optimizer, loss='mse')\n",
    "        # fit model\n",
    "        model.fit(trainX, trainY, epochs=200,batch_size=batch_size, verbose=0)\n",
    "\n",
    "        yhat = model.predict(testX, verbose=0)\n",
    "        RMSE_1=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,0,:]),scaler_target.inverse_transform(yhat[:,0,:])))\n",
    "        RMSE_2=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,1,:]),scaler_target.inverse_transform(yhat[:,1,:])))                                 \n",
    "        RMSE_3=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,2,:]),scaler_target.inverse_transform(yhat[:,2,:])))                                    \n",
    "        RMSE_final=(RMSE_1+RMSE_2+RMSE_3)/3\n",
    "        print('RMSE',RMSE_final)\n",
    "        RMSE_total+=RMSE_final\n",
    "    print('batch_size',batch_size)\n",
    "    print('Mean of RMSE',RMSE_total/repeats)\n",
    "    \n",
    "print('Minutes spent', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 11828.228939566316\n",
      "RMSE 10696.172756150685\n",
      "RMSE 11009.121673687203\n",
      "RMSE 11827.77811212007\n",
      "RMSE 10998.934141319862\n",
      "batch_size 32\n",
      "Mean of RMSE 11272.047124568828\n",
      "RMSE 10440.926397865094\n",
      "RMSE 11484.978044673959\n",
      "RMSE 10635.09754498724\n",
      "RMSE 11783.039275580142\n",
      "RMSE 10271.34313583434\n",
      "batch_size 64\n",
      "Mean of RMSE 10923.076879788156\n",
      "RMSE 10581.682737945135\n",
      "RMSE 10154.382671538775\n",
      "RMSE 10473.774334694357\n",
      "RMSE 9760.157863980397\n",
      "RMSE 10456.833401097605\n",
      "batch_size 128\n",
      "Mean of RMSE 10285.366201851253\n",
      "RMSE 9381.105149774767\n",
      "RMSE 10362.603475116908\n",
      "RMSE 9816.874886979704\n",
      "RMSE 10294.377094630825\n",
      "RMSE 9076.757678042279\n",
      "batch_size 256\n",
      "Mean of RMSE 9786.343656908899\n",
      "RMSE 15275.181458322208\n",
      "RMSE 11060.032850307869\n",
      "RMSE 10744.798125018899\n",
      "RMSE 10845.491553484142\n",
      "RMSE 9604.836277856703\n",
      "batch_size 512\n",
      "Mean of RMSE 11506.068052997964\n",
      "RMSE 9581.184345171438\n",
      "RMSE 11159.999355870592\n",
      "RMSE 11881.73366843545\n",
      "RMSE 10888.25903934925\n",
      "RMSE 11126.220708700317\n",
      "batch_size 1024\n",
      "Mean of RMSE 10927.47942350541\n",
      "Minutes spent 2223.4278888344766\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "batch_sizes = [32,64,128,256,512,1024]\n",
    "neurons = 64\n",
    "for batch_size in batch_sizes:\n",
    "\n",
    "    RMSE_total=0\n",
    "    for i in range(repeats):\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(neurons, activation='relu', input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "        model.add(RepeatVector(3))\n",
    "        model.add(LSTM(neurons, activation='relu', return_sequences=True))\n",
    "        model.add(TimeDistributed(Dense(1)))\n",
    "        optimizer = optimizers.Adam(lr=0.001)\n",
    "        model.compile(optimizer=optimizer, loss='mse')\n",
    "        # fit model\n",
    "        model.fit(trainX, trainY, epochs=200,batch_size=batch_size, verbose=0)\n",
    "\n",
    "        yhat = model.predict(testX, verbose=0)\n",
    "        RMSE_1=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,0,:]),scaler_target.inverse_transform(yhat[:,0,:])))\n",
    "        RMSE_2=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,1,:]),scaler_target.inverse_transform(yhat[:,1,:])))                                 \n",
    "        RMSE_3=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,2,:]),scaler_target.inverse_transform(yhat[:,2,:])))                                    \n",
    "        RMSE_final=(RMSE_1+RMSE_2+RMSE_3)/3\n",
    "        print('RMSE',RMSE_final)\n",
    "        RMSE_total+=RMSE_final\n",
    "    print('batch_size',batch_size)\n",
    "    print('Mean of RMSE',RMSE_total/repeats)\n",
    "    \n",
    "print('Minutes spent', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 9829.98993617369\n",
      "RMSE 10914.725772146701\n",
      "RMSE 9716.496626569156\n",
      "RMSE 10912.019298478064\n",
      "RMSE 10562.103593319347\n",
      "batch_size 32\n",
      "Mean of RMSE 10387.067045337393\n",
      "RMSE 10006.670068157184\n",
      "RMSE 10253.375221942542\n",
      "RMSE 10639.92908836348\n",
      "RMSE 9724.89604963478\n",
      "RMSE 10906.119648473923\n",
      "batch_size 64\n",
      "Mean of RMSE 10306.198015314381\n",
      "RMSE 10324.817259196532\n",
      "RMSE 10306.601676858269\n",
      "RMSE 10527.966649202484\n",
      "RMSE 9916.881996978353\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "batch_sizes = [32,64,128,256,512,1024]\n",
    "neurons = 128\n",
    "for batch_size in batch_sizes:\n",
    "\n",
    "    RMSE_total=0\n",
    "    for i in range(repeats):\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(neurons, activation='relu', input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "        model.add(RepeatVector(3))\n",
    "        model.add(LSTM(neurons, activation='relu', return_sequences=True))\n",
    "        model.add(TimeDistributed(Dense(1)))\n",
    "        optimizer = optimizers.Adam(lr=0.001)\n",
    "        model.compile(optimizer=optimizer, loss='mse')\n",
    "        # fit model\n",
    "        model.fit(trainX, trainY, epochs=200,batch_size=batch_size, verbose=0)\n",
    "\n",
    "        yhat = model.predict(testX, verbose=0)\n",
    "        RMSE_1=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,0,:]),scaler_target.inverse_transform(yhat[:,0,:])))\n",
    "        RMSE_2=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,1,:]),scaler_target.inverse_transform(yhat[:,1,:])))                                 \n",
    "        RMSE_3=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,2,:]),scaler_target.inverse_transform(yhat[:,2,:])))                                    \n",
    "        RMSE_final=(RMSE_1+RMSE_2+RMSE_3)/3\n",
    "        print('RMSE',RMSE_final)\n",
    "        RMSE_total+=RMSE_final\n",
    "    print('batch_size',batch_size)\n",
    "    print('Mean of RMSE',RMSE_total/repeats)\n",
    "    \n",
    "print('Minutes spent', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 9851.995443265667\n",
      "RMSE 9305.662765772251\n",
      "RMSE 10908.717812039633\n",
      "RMSE 10555.063212735704\n",
      "RMSE 10374.389590965147\n",
      "batch_size 32\n",
      "Mean of RMSE 10199.16576495568\n",
      "RMSE 10341.370390631584\n",
      "RMSE 10097.836136888931\n",
      "RMSE 10482.708233384052\n",
      "RMSE 10910.953339582296\n",
      "RMSE 10400.805726631143\n",
      "batch_size 64\n",
      "Mean of RMSE 10446.734765423602\n",
      "RMSE 10278.977163622281\n",
      "RMSE 9506.124411729164\n",
      "RMSE 9980.626340815526\n",
      "RMSE 9867.71611993979\n",
      "RMSE 9812.565226929773\n",
      "batch_size 128\n",
      "Mean of RMSE 9889.201852607306\n",
      "RMSE 10595.831871157521\n",
      "RMSE 9869.71542923583\n",
      "RMSE 10117.471280229278\n",
      "RMSE 9817.723006485016\n",
      "RMSE 9562.429701428564\n",
      "batch_size 256\n",
      "Mean of RMSE 9992.634257707241\n",
      "RMSE 9353.827426878495\n",
      "RMSE 10358.332823615756\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "batch_sizes = [32,64,128,256,512,1024]\n",
    "neurons = 256\n",
    "for batch_size in batch_sizes:\n",
    "\n",
    "    RMSE_total=0\n",
    "    for i in range(repeats):\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(neurons, activation='relu', input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "        model.add(RepeatVector(3))\n",
    "        model.add(LSTM(neurons, activation='relu', return_sequences=True))\n",
    "        model.add(TimeDistributed(Dense(1)))\n",
    "        optimizer = optimizers.Adam(lr=0.001)\n",
    "        model.compile(optimizer=optimizer, loss='mse')\n",
    "        # fit model\n",
    "        model.fit(trainX, trainY, epochs=200,batch_size=batch_size, verbose=0)\n",
    "\n",
    "        yhat = model.predict(testX, verbose=0)\n",
    "        RMSE_1=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,0,:]),scaler_target.inverse_transform(yhat[:,0,:])))\n",
    "        RMSE_2=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,1,:]),scaler_target.inverse_transform(yhat[:,1,:])))                                 \n",
    "        RMSE_3=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,2,:]),scaler_target.inverse_transform(yhat[:,2,:])))                                    \n",
    "        RMSE_final=(RMSE_1+RMSE_2+RMSE_3)/3\n",
    "        print('RMSE',RMSE_final)\n",
    "        RMSE_total+=RMSE_final\n",
    "    print('batch_size',batch_size)\n",
    "    print('Mean of RMSE',RMSE_total/repeats)\n",
    "    \n",
    "print('Minutes spent', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 10072.204378823706\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "batch_sizes = [32,64,128,256,512,1024]\n",
    "neurons = 512\n",
    "for batch_size in batch_sizes:\n",
    "\n",
    "    RMSE_total=0\n",
    "    for i in range(repeats):\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(neurons, activation='relu', input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "        model.add(RepeatVector(3))\n",
    "        model.add(LSTM(neurons, activation='relu', return_sequences=True))\n",
    "        model.add(TimeDistributed(Dense(1)))\n",
    "        optimizer = optimizers.Adam(lr=0.001)\n",
    "        model.compile(optimizer=optimizer, loss='mse')\n",
    "        # fit model\n",
    "        model.fit(trainX, trainY, epochs=200,batch_size=batch_size, verbose=0)\n",
    "\n",
    "        yhat = model.predict(testX, verbose=0)\n",
    "        RMSE_1=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,0,:]),scaler_target.inverse_transform(yhat[:,0,:])))\n",
    "        RMSE_2=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,1,:]),scaler_target.inverse_transform(yhat[:,1,:])))                                 \n",
    "        RMSE_3=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,2,:]),scaler_target.inverse_transform(yhat[:,2,:])))                                    \n",
    "        RMSE_final=(RMSE_1+RMSE_2+RMSE_3)/3\n",
    "        print('RMSE',RMSE_final)\n",
    "        RMSE_total+=RMSE_final\n",
    "    print('batch_size',batch_size)\n",
    "    print('Mean of RMSE',RMSE_total/repeats)\n",
    "    \n",
    "print('Minutes spent', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "batch_sizes = [32,64,128,256,512,1024]\n",
    "neurons = 768\n",
    "for batch_size in batch_sizes:\n",
    "\n",
    "    RMSE_total=0\n",
    "    for i in range(repeats):\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(neurons, activation='relu', input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "        model.add(RepeatVector(3))\n",
    "        model.add(LSTM(neurons, activation='relu', return_sequences=True))\n",
    "        model.add(TimeDistributed(Dense(1)))\n",
    "        optimizer = optimizers.Adam(lr=0.001)\n",
    "        model.compile(optimizer=optimizer, loss='mse')\n",
    "        # fit model\n",
    "        model.fit(trainX, trainY, epochs=200,batch_size=batch_size, verbose=0)\n",
    "\n",
    "        yhat = model.predict(testX, verbose=0)\n",
    "        RMSE_1=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,0,:]),scaler_target.inverse_transform(yhat[:,0,:])))\n",
    "        RMSE_2=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,1,:]),scaler_target.inverse_transform(yhat[:,1,:])))                                 \n",
    "        RMSE_3=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,2,:]),scaler_target.inverse_transform(yhat[:,2,:])))                                    \n",
    "        RMSE_final=(RMSE_1+RMSE_2+RMSE_3)/3\n",
    "        print('RMSE',RMSE_final)\n",
    "        RMSE_total+=RMSE_final\n",
    "    print('batch_size',batch_size)\n",
    "    print('Mean of RMSE',RMSE_total/repeats)\n",
    "    \n",
    "print('Minutes spent', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "batch_sizes = [32,64,128,256,512,1024]\n",
    "neurons = 1024\n",
    "for batch_size in batch_sizes:\n",
    "\n",
    "    RMSE_total=0\n",
    "    for i in range(repeats):\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(neurons, activation='relu', input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "        model.add(RepeatVector(3))\n",
    "        model.add(LSTM(neurons, activation='relu', return_sequences=True))\n",
    "        model.add(TimeDistributed(Dense(1)))\n",
    "        optimizer = optimizers.Adam(lr=0.001)\n",
    "        model.compile(optimizer=optimizer, loss='mse')\n",
    "        # fit model\n",
    "        model.fit(trainX, trainY, epochs=200,batch_size=batch_size, verbose=0)\n",
    "\n",
    "        yhat = model.predict(testX, verbose=0)\n",
    "        RMSE_1=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,0,:]),scaler_target.inverse_transform(yhat[:,0,:])))\n",
    "        RMSE_2=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,1,:]),scaler_target.inverse_transform(yhat[:,1,:])))                                 \n",
    "        RMSE_3=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,2,:]),scaler_target.inverse_transform(yhat[:,2,:])))                                    \n",
    "        RMSE_final=(RMSE_1+RMSE_2+RMSE_3)/3\n",
    "        print('RMSE',RMSE_final)\n",
    "        RMSE_total+=RMSE_final\n",
    "    print('batch_size',batch_size)\n",
    "    print('Mean of RMSE',RMSE_total/repeats)\n",
    "    \n",
    "print('Minutes spent', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion: 50 neurons, defaut batch size ,30 epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1.3.1 tune num of hidden layers-have same no. of hidden units in every layer(usually the more the better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 8761.039649402788\n",
      "RMSE 9228.482170624904\n",
      "RMSE 9274.808146726742\n",
      "RMSE 9345.47153080255\n",
      "RMSE 9686.094368912234\n",
      "Layers 1\n",
      "Mean of RMSE 9259.179173293844\n",
      "Minutes spent 88.99117235342662\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "RMSE_total=0\n",
    "for i in range(repeats):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, activation='relu', input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "    model.add(RepeatVector(3))\n",
    "    model.add(LSTM(neurons, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    optimizer = optimizers.Adam(lr=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    # fit model\n",
    "    model.fit(trainX, trainY, epochs=30, verbose=0)\n",
    "\n",
    "    yhat = model.predict(testX, verbose=0)\n",
    "    RMSE_1=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,0,:]),scaler_target.inverse_transform(yhat[:,0,:])))\n",
    "    RMSE_2=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,1,:]),scaler_target.inverse_transform(yhat[:,1,:])))                                 \n",
    "    RMSE_3=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,2,:]),scaler_target.inverse_transform(yhat[:,2,:])))                                    \n",
    "    RMSE_final=(RMSE_1+RMSE_2+RMSE_3)/3\n",
    "    print('RMSE',RMSE_final)\n",
    "    RMSE_total+=RMSE_final\n",
    "print('Layers',1)\n",
    "print('Mean of RMSE',RMSE_total/repeats)\n",
    "\n",
    "print('Minutes spent', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 8840.999043712838\n",
      "RMSE 10042.983391359581\n",
      "RMSE 9888.904239023757\n",
      "RMSE 9499.866640070073\n",
      "RMSE 9529.16685853069\n",
      "Layers 2\n",
      "Mean of RMSE 9560.384034539387\n",
      "Minutes spent 30.73367512623469\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "RMSE_total=0\n",
    "for i in range(repeats):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, activation='relu', return_sequences=True, input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "    model.add(LSTM(neurons, activation='relu'))\n",
    "    model.add(RepeatVector(3))\n",
    "    model.add(LSTM(neurons, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    optimizer = optimizers.Adam(lr=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    # fit model\n",
    "    model.fit(trainX, trainY, epochs=30, verbose=0)\n",
    "\n",
    "    yhat = model.predict(testX, verbose=0)\n",
    "    RMSE_1=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,0,:]),scaler_target.inverse_transform(yhat[:,0,:])))\n",
    "    RMSE_2=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,1,:]),scaler_target.inverse_transform(yhat[:,1,:])))                                 \n",
    "    RMSE_3=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,2,:]),scaler_target.inverse_transform(yhat[:,2,:])))                                    \n",
    "    RMSE_final=(RMSE_1+RMSE_2+RMSE_3)/3\n",
    "    print('RMSE',RMSE_final)\n",
    "    RMSE_total+=RMSE_final\n",
    "print('Layers',2)\n",
    "print('Mean of RMSE',RMSE_total/repeats)\n",
    "\n",
    "print('Minutes spent', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 9137.104590092711\n",
      "RMSE 8680.9866074898\n",
      "RMSE 9015.842790505705\n",
      "RMSE 9023.02138076393\n",
      "RMSE 8968.711048332516\n",
      "Layers 3\n",
      "Mean of RMSE 8965.133283436933\n",
      "Minutes spent 34.76443761587143\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "RMSE_total=0\n",
    "for i in range(repeats):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, activation='relu', return_sequences=True, input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "    model.add(LSTM(neurons, activation='relu', return_sequences=True))\n",
    "    model.add(LSTM(neurons, activation='relu'))\n",
    "    model.add(RepeatVector(3))\n",
    "    model.add(LSTM(neurons, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    optimizer = optimizers.Adam(lr=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    # fit model\n",
    "    model.fit(trainX, trainY, epochs=30, verbose=0)\n",
    "\n",
    "    yhat = model.predict(testX, verbose=0)\n",
    "    RMSE_1=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,0,:]),scaler_target.inverse_transform(yhat[:,0,:])))\n",
    "    RMSE_2=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,1,:]),scaler_target.inverse_transform(yhat[:,1,:])))                                 \n",
    "    RMSE_3=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,2,:]),scaler_target.inverse_transform(yhat[:,2,:])))                                    \n",
    "    RMSE_final=(RMSE_1+RMSE_2+RMSE_3)/3\n",
    "    print('RMSE',RMSE_final)\n",
    "    RMSE_total+=RMSE_final\n",
    "print('Layers',3)\n",
    "print('Mean of RMSE',RMSE_total/repeats)\n",
    "\n",
    "print('Minutes spent', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 9363.606098059878\n",
      "RMSE 10413.825762012308\n",
      "RMSE 9822.30502372056\n",
      "RMSE 9398.648580377778\n",
      "RMSE 9633.153329826491\n",
      "Layers 4\n",
      "Mean of RMSE 9726.307758799403\n",
      "Minutes spent 50.859784909089406\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "RMSE_total=0\n",
    "for i in range(repeats):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, activation='relu', return_sequences=True, input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "    model.add(LSTM(neurons, activation='relu', return_sequences=True))\n",
    "    model.add(LSTM(neurons, activation='relu', return_sequences=True))\n",
    "    model.add(LSTM(neurons, activation='relu'))\n",
    "    model.add(RepeatVector(3))\n",
    "    model.add(LSTM(neurons, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    optimizer = optimizers.Adam(lr=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    # fit model\n",
    "    model.fit(trainX, trainY, epochs=30, verbose=0)\n",
    "\n",
    "    yhat = model.predict(testX, verbose=0)\n",
    "    RMSE_1=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,0,:]),scaler_target.inverse_transform(yhat[:,0,:])))\n",
    "    RMSE_2=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,1,:]),scaler_target.inverse_transform(yhat[:,1,:])))                                 \n",
    "    RMSE_3=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,2,:]),scaler_target.inverse_transform(yhat[:,2,:])))                                    \n",
    "    RMSE_final=(RMSE_1+RMSE_2+RMSE_3)/3\n",
    "    print('RMSE',RMSE_final)\n",
    "    RMSE_total+=RMSE_final\n",
    "print('Layers',4)\n",
    "print('Mean of RMSE',RMSE_total/repeats)\n",
    "\n",
    "print('Minutes spent', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 11665.231165603109\n",
      "RMSE 8838.098316424774\n",
      "RMSE 9201.4278835823\n",
      "RMSE 9365.436709477852\n",
      "RMSE 10220.796064481023\n",
      "Layers 5\n",
      "Mean of RMSE 9858.198027913812\n",
      "Minutes spent 80.75290323098501\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "RMSE_total=0\n",
    "for i in range(repeats):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, activation='relu', return_sequences=True, input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "    model.add(LSTM(neurons, activation='relu', return_sequences=True))\n",
    "    model.add(LSTM(neurons, activation='relu', return_sequences=True))\n",
    "    model.add(LSTM(neurons, activation='relu', return_sequences=True))\n",
    "    model.add(LSTM(neurons, activation='relu'))\n",
    "    model.add(RepeatVector(3))\n",
    "    model.add(LSTM(neurons, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    optimizer = optimizers.Adam(lr=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    # fit model\n",
    "    model.fit(trainX, trainY, epochs=30, verbose=0)\n",
    "\n",
    "    yhat = model.predict(testX, verbose=0)\n",
    "    RMSE_1=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,0,:]),scaler_target.inverse_transform(yhat[:,0,:])))\n",
    "    RMSE_2=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,1,:]),scaler_target.inverse_transform(yhat[:,1,:])))                                 \n",
    "    RMSE_3=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,2,:]),scaler_target.inverse_transform(yhat[:,2,:])))                                    \n",
    "    RMSE_final=(RMSE_1+RMSE_2+RMSE_3)/3\n",
    "    print('RMSE',RMSE_final)\n",
    "    RMSE_total+=RMSE_final\n",
    "print('Layers',5)\n",
    "print('Mean of RMSE',RMSE_total/repeats)\n",
    "\n",
    "print('Minutes spent', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:3 layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3.2 tune learning rate decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 8808.171808131001\n",
      "RMSE 8872.074060385165\n",
      "RMSE 8723.43800371222\n",
      "RMSE 9155.679608547654\n",
      "RMSE 8936.064690696725\n",
      "decay 0\n",
      "Mean of RMSE 8899.085634294552\n",
      "RMSE 9272.458635584831\n",
      "RMSE 9297.87851538039\n",
      "RMSE 9050.942919378962\n",
      "RMSE 9394.505872241163\n",
      "RMSE 9349.973182322408\n",
      "decay 0.3\n",
      "Mean of RMSE 9273.15182498155\n",
      "RMSE 9518.236861398063\n",
      "RMSE 9224.862916080745\n",
      "RMSE 9936.400081643136\n",
      "RMSE 9342.675826893581\n",
      "RMSE 9380.866820090754\n",
      "decay 0.5\n",
      "Mean of RMSE 9480.608501221257\n",
      "RMSE 9362.975801142911\n",
      "RMSE 9490.907338737556\n",
      "RMSE 9618.466644890928\n",
      "RMSE 9223.784074950901\n",
      "RMSE 9543.060334109126\n",
      "decay 0.7\n",
      "Mean of RMSE 9447.838838766284\n",
      "RMSE 8999.802851724216\n",
      "RMSE 9373.347807889542\n",
      "RMSE 9285.34224178081\n",
      "RMSE 9154.950522862815\n",
      "RMSE 9126.902738879573\n",
      "decay 1.0\n",
      "Mean of RMSE 9188.069232627391\n",
      "RMSE 9178.027125359713\n",
      "RMSE 9032.974462075166\n",
      "RMSE 9320.808261083997\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "decays = [0,0.3,0.5,0.7,1.0,1.3,1.5]\n",
    "\n",
    "for decay in decays:\n",
    "\n",
    "    RMSE_total=0\n",
    "    for i in range(repeats):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(neurons, activation='relu', return_sequences=True, input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "        model.add(LSTM(neurons, activation='relu', return_sequences=True))\n",
    "        model.add(LSTM(neurons, activation='relu'))\n",
    "        model.add(RepeatVector(3))\n",
    "        model.add(LSTM(neurons, activation='relu', return_sequences=True))\n",
    "        model.add(TimeDistributed(Dense(1)))\n",
    "        optimizer = optimizers.Adam(decay=decay,lr=0.001)\n",
    "        model.compile(optimizer=optimizer, loss='mse')\n",
    "        # fit model\n",
    "        model.fit(trainX, trainY, epochs=30, verbose=0)\n",
    "\n",
    "        yhat = model.predict(testX, verbose=0)\n",
    "        RMSE_1=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,0,:]),scaler_target.inverse_transform(yhat[:,0,:])))\n",
    "        RMSE_2=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,1,:]),scaler_target.inverse_transform(yhat[:,1,:])))                                 \n",
    "        RMSE_3=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,2,:]),scaler_target.inverse_transform(yhat[:,2,:])))                                    \n",
    "        RMSE_final=(RMSE_1+RMSE_2+RMSE_3)/3\n",
    "        print('RMSE',RMSE_final)\n",
    "        RMSE_total+=RMSE_final\n",
    "    print('decay',decay)\n",
    "    print('Mean of RMSE',RMSE_total/repeats)\n",
    "    \n",
    "print('Minutes spent', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 tune activation and weights initialization(he+relu;tanh+Xavier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 8809.143285717306\n",
      "RMSE 8681.741996213248\n",
      "RMSE 9373.262986698714\n",
      "RMSE 9264.314680005979\n",
      "RMSE 9676.064970104415\n",
      "activation relu init_mode uniform\n",
      "Mean of RMSE 9160.905583747932\n",
      "RMSE 8723.92726195268\n",
      "RMSE 8849.977422419548\n",
      "RMSE 8889.846214671767\n",
      "RMSE 8824.04234756667\n",
      "RMSE 9050.984614524974\n",
      "activation relu init_mode normal\n",
      "Mean of RMSE 8867.755572227128\n",
      "RMSE 9019.498561085327\n",
      "RMSE 9316.221802491013\n",
      "RMSE 9923.375440384247\n",
      "RMSE 9408.197717834873\n",
      "RMSE 9137.336599075696\n",
      "activation relu init_mode zero\n",
      "Mean of RMSE 9360.92602417423\n",
      "RMSE 8964.077952176924\n",
      "RMSE 9753.217149034774\n",
      "RMSE 9286.848487306532\n",
      "RMSE 9248.177034353075\n",
      "RMSE 8725.442352846787\n",
      "activation relu init_mode glorot_uniform\n",
      "Mean of RMSE 9195.552595143618\n",
      "RMSE 8766.655563279635\n",
      "RMSE 8915.326937812031\n",
      "RMSE 9511.62392674853\n",
      "RMSE 9252.286085916145\n",
      "RMSE 9453.58716461466\n",
      "activation relu init_mode he_normal\n",
      "Mean of RMSE 9179.895935674202\n",
      "RMSE 9309.248221068518\n",
      "RMSE 11113.454801436694\n",
      "RMSE 9832.12034748002\n",
      "RMSE 8796.02500436404\n",
      "RMSE 8817.846472752155\n",
      "activation relu init_mode he_uniform\n",
      "Mean of RMSE 9573.738969420285\n",
      "Minutes spent 402.51613048712414\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "init_modes = ['uniform',  'normal', 'zero', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "activation ='relu'\n",
    "\n",
    "start = time.time()\n",
    "for init_mode in init_modes:\n",
    "\n",
    "    RMSE_total=0\n",
    "    for i in range(repeats):\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation,return_sequences=True, input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "        model.add(LSTM(neurons, kernel_initializer=init_mode, activation=activation, return_sequences=True))\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation))\n",
    "        model.add(RepeatVector(3))\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation, return_sequences=True))\n",
    "        model.add(TimeDistributed(Dense(1)))\n",
    "        optimizer = optimizers.Adam(decay=0,lr=0.001)\n",
    "        model.compile(optimizer=optimizer, loss='mse')\n",
    "        # fit model\n",
    "        model.fit(trainX, trainY, epochs=30, verbose=0)\n",
    "\n",
    "        yhat = model.predict(testX, verbose=0)\n",
    "        RMSE_1=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,0,:]),scaler_target.inverse_transform(yhat[:,0,:])))\n",
    "        RMSE_2=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,1,:]),scaler_target.inverse_transform(yhat[:,1,:])))                                 \n",
    "        RMSE_3=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,2,:]),scaler_target.inverse_transform(yhat[:,2,:])))                                    \n",
    "        RMSE_final=(RMSE_1+RMSE_2+RMSE_3)/3\n",
    "        print('RMSE',RMSE_final)\n",
    "        RMSE_total+=RMSE_final\n",
    "    print('activation',activation,'init_mode',init_mode)\n",
    "    print('Mean of RMSE',RMSE_total/repeats)\n",
    "    \n",
    "print('Minutes spent', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 9920.11046217443\n",
      "RMSE 9071.962543625172\n",
      "RMSE 9863.831517323057\n",
      "RMSE 8860.467336916603\n",
      "RMSE 8942.554703053096\n",
      "activation softmax init_mode uniform\n",
      "Mean of RMSE 9331.785312618473\n",
      "RMSE 9848.29151955747\n",
      "RMSE 9914.5612269324\n",
      "RMSE 9339.280881677028\n",
      "RMSE 9112.44471057891\n",
      "RMSE 9551.974338755277\n",
      "activation softmax init_mode normal\n",
      "Mean of RMSE 9553.310535500215\n",
      "RMSE 8865.217912663307\n",
      "RMSE 11044.285941294795\n",
      "RMSE 9825.94237948299\n",
      "RMSE 10770.716081392413\n",
      "RMSE 9890.38733310788\n",
      "activation softmax init_mode zero\n",
      "Mean of RMSE 10079.309929588277\n",
      "RMSE 8965.061095121162\n",
      "RMSE 8845.983965500183\n",
      "RMSE 10181.769153418429\n",
      "RMSE 9190.497757506113\n",
      "RMSE 9582.763636981757\n",
      "activation softmax init_mode glorot_uniform\n",
      "Mean of RMSE 9353.215121705529\n",
      "RMSE 9468.383384548093\n",
      "RMSE 9939.907519611756\n",
      "RMSE 9934.292941834126\n",
      "RMSE 9745.142148200748\n",
      "RMSE 9525.546641623621\n",
      "activation softmax init_mode he_normal\n",
      "Mean of RMSE 9722.654527163668\n",
      "RMSE 9463.519250489016\n",
      "RMSE 10071.624874914902\n",
      "RMSE 9750.593304390357\n",
      "RMSE 10135.316807417725\n",
      "RMSE 10050.915580230621\n",
      "activation softmax init_mode he_uniform\n",
      "Mean of RMSE 9894.393963488523\n",
      "Minutes spent 1614.0089130242666\n"
     ]
    }
   ],
   "source": [
    "init_modes = ['uniform',  'normal', 'zero', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "activation ='softmax'\n",
    "\n",
    "start = time.time()\n",
    "for init_mode in init_modes:\n",
    "\n",
    "    RMSE_total=0\n",
    "    for i in range(repeats):\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation,return_sequences=True, input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "        model.add(LSTM(neurons, kernel_initializer=init_mode, activation=activation, return_sequences=True))\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation))\n",
    "        model.add(RepeatVector(3))\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation, return_sequences=True))\n",
    "        model.add(TimeDistributed(Dense(1)))\n",
    "        optimizer = optimizers.Adam(decay=0,lr=0.001)\n",
    "        model.compile(optimizer=optimizer, loss='mse')\n",
    "        # fit model\n",
    "        model.fit(trainX, trainY, epochs=30, verbose=0)\n",
    "\n",
    "        yhat = model.predict(testX, verbose=0)\n",
    "        RMSE_1=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,0,:]),scaler_target.inverse_transform(yhat[:,0,:])))\n",
    "        RMSE_2=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,1,:]),scaler_target.inverse_transform(yhat[:,1,:])))                                 \n",
    "        RMSE_3=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,2,:]),scaler_target.inverse_transform(yhat[:,2,:])))                                    \n",
    "        RMSE_final=(RMSE_1+RMSE_2+RMSE_3)/3\n",
    "        print('RMSE',RMSE_final)\n",
    "        RMSE_total+=RMSE_final\n",
    "    print('activation',activation,'init_mode',init_mode)\n",
    "    print('Mean of RMSE',RMSE_total/repeats)\n",
    "    \n",
    "print('Minutes spent', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 9805.300008593937\n",
      "RMSE 8821.03164676623\n",
      "RMSE 10254.98033322049\n",
      "RMSE 9267.685128386285\n",
      "RMSE 10857.57809544548\n",
      "activation softplus init_mode uniform\n",
      "Mean of RMSE 9801.315042482485\n",
      "RMSE 10144.659764828444\n",
      "RMSE 10080.369012717298\n",
      "RMSE 9204.897242250796\n",
      "RMSE 8771.654157869905\n",
      "RMSE 9189.109626759348\n",
      "activation softplus init_mode normal\n",
      "Mean of RMSE 9478.137960885157\n",
      "RMSE 9411.668544840046\n",
      "RMSE 9049.31785162634\n",
      "RMSE 11458.619295247574\n",
      "RMSE 8942.194457611091\n",
      "RMSE 11464.791236870362\n",
      "activation softplus init_mode zero\n",
      "Mean of RMSE 10065.318277239083\n",
      "RMSE 9840.637066233305\n",
      "RMSE 9521.234414560815\n",
      "RMSE 13057.402131451834\n",
      "RMSE 10317.78701325087\n",
      "RMSE 8955.101829685322\n",
      "activation softplus init_mode glorot_uniform\n",
      "Mean of RMSE 10338.432491036428\n",
      "RMSE 14389.390651976011\n",
      "RMSE 12856.83473270661\n",
      "RMSE 9951.493707372354\n",
      "RMSE 9667.006108814183\n",
      "RMSE 11524.673458466203\n",
      "activation softplus init_mode he_normal\n",
      "Mean of RMSE 11677.879731867073\n",
      "RMSE 11688.032798373024\n",
      "RMSE 8817.635135961651\n",
      "RMSE 10099.924345179272\n",
      "RMSE 9735.957915069199\n",
      "RMSE 9551.841786677296\n",
      "activation softplus init_mode he_uniform\n",
      "Mean of RMSE 9978.67839625209\n",
      "Minutes spent 3204.394787033399\n"
     ]
    }
   ],
   "source": [
    "init_modes = ['uniform',  'normal', 'zero', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "activation ='softplus'\n",
    "\n",
    "start = time.time()\n",
    "for init_mode in init_modes:\n",
    "\n",
    "    RMSE_total=0\n",
    "    for i in range(repeats):\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation,return_sequences=True, input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "        model.add(LSTM(neurons, kernel_initializer=init_mode, activation=activation, return_sequences=True))\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation))\n",
    "        model.add(RepeatVector(3))\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation, return_sequences=True))\n",
    "        model.add(TimeDistributed(Dense(1)))\n",
    "        optimizer = optimizers.Adam(decay=0,lr=0.001)\n",
    "        model.compile(optimizer=optimizer, loss='mse')\n",
    "        # fit model\n",
    "        model.fit(trainX, trainY, epochs=30, verbose=0)\n",
    "\n",
    "        yhat = model.predict(testX, verbose=0)\n",
    "        RMSE_1=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,0,:]),scaler_target.inverse_transform(yhat[:,0,:])))\n",
    "        RMSE_2=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,1,:]),scaler_target.inverse_transform(yhat[:,1,:])))                                 \n",
    "        RMSE_3=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,2,:]),scaler_target.inverse_transform(yhat[:,2,:])))                                    \n",
    "        RMSE_final=(RMSE_1+RMSE_2+RMSE_3)/3\n",
    "        print('RMSE',RMSE_final)\n",
    "        RMSE_total+=RMSE_final\n",
    "    print('activation',activation,'init_mode',init_mode)\n",
    "    print('Mean of RMSE',RMSE_total/repeats)\n",
    "    \n",
    "print('Minutes spent', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 9338.725136398121\n",
      "RMSE 8886.985730465569\n",
      "RMSE 9248.20706848716\n",
      "RMSE 9288.021551467638\n",
      "RMSE 9055.044388392274\n",
      "activation tanh init_mode uniform\n",
      "Mean of RMSE 9163.396775042153\n",
      "RMSE 8895.383392801916\n",
      "RMSE 8901.364388604996\n",
      "RMSE 9071.69997100187\n",
      "RMSE 9364.81036789957\n",
      "RMSE 10195.504997880838\n",
      "activation tanh init_mode normal\n",
      "Mean of RMSE 9285.752623637838\n",
      "RMSE 9019.334494843859\n",
      "RMSE 9317.410177903748\n",
      "RMSE 9899.769131330493\n",
      "RMSE 9407.123744779125\n",
      "RMSE 9662.333465541533\n",
      "activation tanh init_mode zero\n",
      "Mean of RMSE 9461.194202879751\n",
      "RMSE 8937.07611109498\n",
      "RMSE 8907.390148602526\n",
      "RMSE 8898.641573726125\n",
      "RMSE 9126.740937811595\n",
      "RMSE 9271.835787392458\n",
      "activation tanh init_mode glorot_uniform\n",
      "Mean of RMSE 9028.336911725535\n",
      "RMSE 9279.59989665024\n",
      "RMSE 8994.119490261493\n",
      "RMSE 9595.098002970595\n",
      "RMSE 8878.772842844486\n",
      "RMSE 8945.0848994339\n",
      "activation tanh init_mode he_normal\n",
      "Mean of RMSE 9138.535026432142\n",
      "RMSE 9069.663276439553\n",
      "RMSE 9178.178826270523\n",
      "RMSE 9006.536964362793\n",
      "RMSE 9025.818847751905\n",
      "RMSE 9283.804063210893\n",
      "activation tanh init_mode he_uniform\n",
      "Mean of RMSE 9112.800395607133\n",
      "Minutes spent 421.155167889595\n"
     ]
    }
   ],
   "source": [
    "init_modes = ['uniform',  'normal', 'zero', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "activation ='tanh'\n",
    "\n",
    "start = time.time()\n",
    "for init_mode in init_modes:\n",
    "\n",
    "    RMSE_total=0\n",
    "    for i in range(repeats):\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation,return_sequences=True, input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "        model.add(LSTM(neurons, kernel_initializer=init_mode, activation=activation, return_sequences=True))\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation))\n",
    "        model.add(RepeatVector(3))\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation, return_sequences=True))\n",
    "        model.add(TimeDistributed(Dense(1)))\n",
    "        optimizer = optimizers.Adam(decay=0,lr=0.001)\n",
    "        model.compile(optimizer=optimizer, loss='mse')\n",
    "        # fit model\n",
    "        model.fit(trainX, trainY, epochs=30, verbose=0)\n",
    "\n",
    "        yhat = model.predict(testX, verbose=0)\n",
    "        RMSE_1=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,0,:]),scaler_target.inverse_transform(yhat[:,0,:])))\n",
    "        RMSE_2=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,1,:]),scaler_target.inverse_transform(yhat[:,1,:])))                                 \n",
    "        RMSE_3=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,2,:]),scaler_target.inverse_transform(yhat[:,2,:])))                                    \n",
    "        RMSE_final=(RMSE_1+RMSE_2+RMSE_3)/3\n",
    "        print('RMSE',RMSE_final)\n",
    "        RMSE_total+=RMSE_final\n",
    "    print('activation',activation,'init_mode',init_mode)\n",
    "    print('Mean of RMSE',RMSE_total/repeats)\n",
    "    \n",
    "print('Minutes spent', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 10316.734782600715\n",
      "RMSE 11649.205291757093\n",
      "RMSE 9456.656973184006\n",
      "RMSE 10412.28019050884\n",
      "RMSE 8788.165577325855\n",
      "activation sigmoid init_mode uniform\n",
      "Mean of RMSE 10124.608563075302\n",
      "RMSE 11153.919260276443\n",
      "RMSE 9157.827620301663\n",
      "RMSE 10031.150577041679\n",
      "RMSE 10180.787426270907\n",
      "RMSE 9964.691171355635\n",
      "activation sigmoid init_mode normal\n",
      "Mean of RMSE 10097.675211049265\n",
      "RMSE 10515.548337513448\n",
      "RMSE 9239.477473092566\n",
      "RMSE 11823.365746572954\n",
      "RMSE 9795.671803821846\n",
      "RMSE 9939.76584663697\n",
      "activation sigmoid init_mode zero\n",
      "Mean of RMSE 10262.765841527556\n",
      "RMSE 8860.042855375885\n",
      "RMSE 8832.672006575158\n",
      "RMSE 8695.133652589195\n",
      "RMSE 10082.958636444871\n",
      "RMSE 10236.58799689021\n",
      "activation sigmoid init_mode glorot_uniform\n",
      "Mean of RMSE 9341.479029575063\n",
      "RMSE 9487.488832988203\n",
      "RMSE 9340.559501787639\n",
      "RMSE 9209.678555213684\n",
      "RMSE 9158.682321179618\n",
      "RMSE 9451.826378043026\n",
      "activation sigmoid init_mode he_normal\n",
      "Mean of RMSE 9329.647117842434\n",
      "RMSE 10287.079116766088\n",
      "RMSE 11104.418388182383\n",
      "RMSE 9092.486735536646\n"
     ]
    }
   ],
   "source": [
    "init_modes = ['uniform',  'normal', 'zero', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "activation ='sigmoid'\n",
    "\n",
    "start = time.time()\n",
    "for init_mode in init_modes:\n",
    "\n",
    "    RMSE_total=0\n",
    "    for i in range(repeats):\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation,return_sequences=True, input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "        model.add(LSTM(neurons, kernel_initializer=init_mode, activation=activation, return_sequences=True))\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation))\n",
    "        model.add(RepeatVector(3))\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation, return_sequences=True))\n",
    "        model.add(TimeDistributed(Dense(1)))\n",
    "        optimizer = optimizers.Adam(decay=0,lr=0.001)\n",
    "        model.compile(optimizer=optimizer, loss='mse')\n",
    "        # fit model\n",
    "        model.fit(trainX, trainY, epochs=30, verbose=0)\n",
    "\n",
    "        yhat = model.predict(testX, verbose=0)\n",
    "        RMSE_1=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,0,:]),scaler_target.inverse_transform(yhat[:,0,:])))\n",
    "        RMSE_2=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,1,:]),scaler_target.inverse_transform(yhat[:,1,:])))                                 \n",
    "        RMSE_3=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,2,:]),scaler_target.inverse_transform(yhat[:,2,:])))                                    \n",
    "        RMSE_final=(RMSE_1+RMSE_2+RMSE_3)/3\n",
    "        print('RMSE',RMSE_final)\n",
    "        RMSE_total+=RMSE_final\n",
    "    print('activation',activation,'init_mode',init_mode)\n",
    "    print('Mean of RMSE',RMSE_total/repeats)\n",
    "    \n",
    "print('Minutes spent', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_modes = ['uniform',  'normal', 'zero', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "activation ='linear'\n",
    "\n",
    "start = time.time()\n",
    "for init_mode in init_modes:\n",
    "\n",
    "    RMSE_total=0\n",
    "    for i in range(repeats):\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation,return_sequences=True, input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "        model.add(LSTM(neurons, kernel_initializer=init_mode, activation=activation, return_sequences=True))\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation))\n",
    "        model.add(RepeatVector(3))\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation, return_sequences=True))\n",
    "        model.add(TimeDistributed(Dense(1)))\n",
    "        optimizer = optimizers.Adam(decay=0,lr=0.001)\n",
    "        model.compile(optimizer=optimizer, loss='mse')\n",
    "        # fit model\n",
    "        model.fit(trainX, trainY, epochs=30, verbose=0)\n",
    "\n",
    "        yhat = model.predict(testX, verbose=0)\n",
    "        RMSE_1=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,0,:]),scaler_target.inverse_transform(yhat[:,0,:])))\n",
    "        RMSE_2=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,1,:]),scaler_target.inverse_transform(yhat[:,1,:])))                                 \n",
    "        RMSE_3=sqrt(mean_squared_error(scaler_target.inverse_transform(testY[:,2,:]),scaler_target.inverse_transform(yhat[:,2,:])))                                    \n",
    "        RMSE_final=(RMSE_1+RMSE_2+RMSE_3)/3\n",
    "        print('RMSE',RMSE_final)\n",
    "        RMSE_total+=RMSE_final\n",
    "    print('activation',activation,'init_mode',init_mode)\n",
    "    print('Mean of RMSE',RMSE_total/repeats)\n",
    "    \n",
    "print('Minutes spent', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5 tune Batch Normalization(use it or not) ??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import BatchNormalization\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Activation, Dense\n",
    "\n",
    "def create_model():\n",
    "\t# create model\n",
    "    model = Sequential()\n",
    "    # layer_1\n",
    "    model.add(Dense(32, input_dim=640,kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.0))\n",
    "    # layer_2\n",
    "    model.add(Dense(32,kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.0))\n",
    "    # layer_3\n",
    "    model.add(Dense(1,kernel_initializer='normal'))\n",
    "\t# Compile model\n",
    "    optimizer = optimizers.Adagrad(decay=0.0) \n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mean_squared_error'])\n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasRegressor(build_fn=create_model, epochs=500, batch_size=256, verbose=0)\n",
    "\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_predict=model.predict(X_test)\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "print('r2_score:')\n",
    "print(r2_score(y_test,y_predict))\n",
    "\n",
    "y_test_origi=scaler_target.inverse_transform(y_test)\n",
    "y_predict=y_predict.reshape(-1, 1)\n",
    "y_predict_origi=scaler_target.inverse_transform(y_predict)\n",
    "\n",
    "print('MAE:')\n",
    "print(mae(y_test_origi, y_predict_origi))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Fit dev set well on cost fuhction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 tune Dropout Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rates = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "weight_constraint =1 \n",
    "\n",
    "for dropout_rate in dropout_rates:\n",
    "\n",
    "    R2Score_total=0\n",
    "    for i in range(repeats):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation,kernel_constraint=max_norm(weight_constraint), input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "         model.add(Dropout(dropout_rate))\n",
    "        model.add(RepeatVector(3))\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation,return_sequences=True))\n",
    "        optimizer = optimizers.Adam(decay=decay)\n",
    "        model.compile(optimizer=optimizer, loss='mse')\n",
    "        # fit model\n",
    "        model.fit(trainX, trainY, epochs=100,batch_size=batch_size, verbose=0)\n",
    "\n",
    "        yhat = model.predict(testX, verbose=0)\n",
    "        print((r2_score(testY[:,0,:],yhat[:,0,:])+r2_score(testY[:,1,:],yhat[:,1,:])+r2_score(testY[:,2,:],yhat[:,2,:]))/3)\n",
    "        R2Score_total+=(r2_score(testY[:,0,:],yhat[:,0,:])+r2_score(testY[:,1,:],yhat[:,1,:])+r2_score(testY[:,2,:],yhat[:,2,:]))/3\n",
    "    print('dropout_rate',dropout_rate)\n",
    "    print('Mean of R2 score',R2Score_total/repeats)\n",
    "    \n",
    "print('Minutes spent', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rates = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "weight_constraint =2 \n",
    "\n",
    "for dropout_rate in dropout_rates:\n",
    "\n",
    "    R2Score_total=0\n",
    "    for i in range(repeats):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation,kernel_constraint=max_norm(weight_constraint), input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "         model.add(Dropout(dropout_rate))\n",
    "        model.add(RepeatVector(3))\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation,return_sequences=True))\n",
    "        optimizer = optimizers.Adam(decay=decay)\n",
    "        model.compile(optimizer=optimizer, loss='mse')\n",
    "        # fit model\n",
    "        model.fit(trainX, trainY, epochs=100,batch_size=batch_size, verbose=0)\n",
    "\n",
    "        yhat = model.predict(testX, verbose=0)\n",
    "        print((r2_score(testY[:,0,:],yhat[:,0,:])+r2_score(testY[:,1,:],yhat[:,1,:])+r2_score(testY[:,2,:],yhat[:,2,:]))/3)\n",
    "        R2Score_total+=(r2_score(testY[:,0,:],yhat[:,0,:])+r2_score(testY[:,1,:],yhat[:,1,:])+r2_score(testY[:,2,:],yhat[:,2,:]))/3\n",
    "    print('dropout_rate',dropout_rate)\n",
    "    print('Mean of R2 score',R2Score_total/repeats)\n",
    "    \n",
    "print('Minutes spent', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rates = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "weight_constraint =3 \n",
    "\n",
    "for dropout_rate in dropout_rates:\n",
    "\n",
    "    R2Score_total=0\n",
    "    for i in range(repeats):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation,kernel_constraint=max_norm(weight_constraint), input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "         model.add(Dropout(dropout_rate))\n",
    "        model.add(RepeatVector(3))\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation,return_sequences=True))\n",
    "        optimizer = optimizers.Adam(decay=decay)\n",
    "        model.compile(optimizer=optimizer, loss='mse')\n",
    "        # fit model\n",
    "        model.fit(trainX, trainY, epochs=100,batch_size=batch_size, verbose=0)\n",
    "\n",
    "        yhat = model.predict(testX, verbose=0)\n",
    "        print((r2_score(testY[:,0,:],yhat[:,0,:])+r2_score(testY[:,1,:],yhat[:,1,:])+r2_score(testY[:,2,:],yhat[:,2,:]))/3)\n",
    "        R2Score_total+=(r2_score(testY[:,0,:],yhat[:,0,:])+r2_score(testY[:,1,:],yhat[:,1,:])+r2_score(testY[:,2,:],yhat[:,2,:]))/3\n",
    "    print('dropout_rate',dropout_rate)\n",
    "    print('Mean of R2 score',R2Score_total/repeats)\n",
    "    \n",
    "print('Minutes spent', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rates = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "weight_constraint =4 \n",
    "\n",
    "for dropout_rate in dropout_rates:\n",
    "\n",
    "    R2Score_total=0\n",
    "    for i in range(repeats):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation,kernel_constraint=max_norm(weight_constraint), input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "         model.add(Dropout(dropout_rate))\n",
    "        model.add(RepeatVector(3))\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation,return_sequences=True))\n",
    "        optimizer = optimizers.Adam(decay=decay)\n",
    "        model.compile(optimizer=optimizer, loss='mse')\n",
    "        # fit model\n",
    "        model.fit(trainX, trainY, epochs=100,batch_size=batch_size, verbose=0)\n",
    "\n",
    "        yhat = model.predict(testX, verbose=0)\n",
    "        print((r2_score(testY[:,0,:],yhat[:,0,:])+r2_score(testY[:,1,:],yhat[:,1,:])+r2_score(testY[:,2,:],yhat[:,2,:]))/3)\n",
    "        R2Score_total+=(r2_score(testY[:,0,:],yhat[:,0,:])+r2_score(testY[:,1,:],yhat[:,1,:])+r2_score(testY[:,2,:],yhat[:,2,:]))/3\n",
    "    print('dropout_rate',dropout_rate)\n",
    "    print('Mean of R2 score',R2Score_total/repeats)\n",
    "    \n",
    "print('Minutes spent', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rates = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "weight_constraint =5\n",
    "\n",
    "for dropout_rate in dropout_rates:\n",
    "\n",
    "    R2Score_total=0\n",
    "    for i in range(repeats):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation,kernel_constraint=max_norm(weight_constraint), input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "         model.add(Dropout(dropout_rate))\n",
    "        model.add(RepeatVector(3))\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation,return_sequences=True))\n",
    "        optimizer = optimizers.Adam(decay=decay)\n",
    "        model.compile(optimizer=optimizer, loss='mse')\n",
    "        # fit model\n",
    "        model.fit(trainX, trainY, epochs=100,batch_size=batch_size, verbose=0)\n",
    "\n",
    "        yhat = model.predict(testX, verbose=0)\n",
    "        print((r2_score(testY[:,0,:],yhat[:,0,:])+r2_score(testY[:,1,:],yhat[:,1,:])+r2_score(testY[:,2,:],yhat[:,2,:]))/3)\n",
    "        R2Score_total+=(r2_score(testY[:,0,:],yhat[:,0,:])+r2_score(testY[:,1,:],yhat[:,1,:])+r2_score(testY[:,2,:],yhat[:,2,:]))/3\n",
    "    print('dropout_rate',dropout_rate)\n",
    "    print('Mean of R2 score',R2Score_total/repeats)\n",
    "    \n",
    "print('Minutes spent', (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 tune epoch, and re-tune learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [10, 50, 100,300,500,700,1000]\n",
    "learn_rate = \n",
    "\n",
    "for epoch in epochs:\n",
    "\n",
    "    R2Score_total=0\n",
    "    for i in range(repeats):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation,kernel_constraint=max_norm(weight_constraint), input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "         model.add(Dropout(dropout_rate))\n",
    "        model.add(RepeatVector(3))\n",
    "        model.add(LSTM(neurons,kernel_initializer=init_mode, activation=activation,return_sequences=True))\n",
    "        optimizer = optimizers.Adam(lr=learn_rate)\n",
    "        model.compile(optimizer=optimizer, loss='mse')\n",
    "        # fit model\n",
    "        model.fit(trainX, trainY, epochs=epoch,batch_size=batch_size, verbose=0)\n",
    "\n",
    "        yhat = model.predict(testX, verbose=0)\n",
    "        print((r2_score(testY[:,0,:],yhat[:,0,:])+r2_score(testY[:,1,:],yhat[:,1,:])+r2_score(testY[:,2,:],yhat[:,2,:]))/3)\n",
    "        R2Score_total+=(r2_score(testY[:,0,:],yhat[:,0,:])+r2_score(testY[:,1,:],yhat[:,1,:])+r2_score(testY[:,2,:],yhat[:,2,:]))/3\n",
    "    print('epoch',epoch)\n",
    "    print('Mean of R2 score',R2Score_total/repeats)\n",
    "    \n",
    "print('Minutes spent', (time.time() - start)/60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
